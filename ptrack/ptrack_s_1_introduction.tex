\section{Introduction}

The accessibility to supercomputers with increasing computing power has enabled scientists to simulate physical phenomena of unprecedented complexity and resolution. These simulations generate large-scale time-varying data that can take tera- or even peta-bytes of space to preserve. Such storage requirement will be not sustainable towards the forthcoming exascale computing. One promising solution to the problem is to reduce the data by storing only features of interest. Extracted features require storage space that can be several orders of magnitude smaller than raw data.

However, it is a non-trivial task to extract and track features embedded in large data. Large simulation data are typically presented and processed in a distributed fashion, simply because of the shear size. A feature can span over multiple distributed data blocks, and its distribution can evolve over time. Existing research effort on feature-based data visualization has mostly focused on extracting features using quantitative measures, such as size, location, shape, and topology information. These methods can extract partial features among individual data blocks, but cannot directly assemble partial features to provide integrated descriptions, unless the distribution of partial features can be captured and traced efficiently over time.

%These measures cannot be applied to distributed volumetric data directly since volumetric features are consist of certain amount of voxels, and are very likely to span over distributed data blocks as they evolve over time. Therefore existing quantitative measures of partial data scattered across different data blocks cannot be used to describe an integrated feature, unless the distribution of partial features can be obtained beforehand.

Efficiently capturing the distribution of features is challenging with respect to increasing numbers of features and computing nodes. In this paper, we present a scalable approach to generating feature information and tracking feature connectivity information using parallel machines. Compared to the existing approaches that gather the global feature information in a single host node, our approach only involves local covered data blocks of target features. This requires least communication overhead and avoids the potential link contention. We demonstrate the effectiveness and scalability of our method with two vortical flow data sets on large parallel supercomputers with up to 16384 processors.

%To obtain the distribution information of features, a connectivity graph of each feature should be generated and maintained. In this paper, we present an approach to gathering feature residual information and track connectivity information using parallel graphs. Comparing to the existing approaches that generate and maintain the global feature information in a single host node, our approach can be done locally that only involves residual data blocks of target features. This requires least communication overhead and avoids the potential link contention. We demonstrate the effectiveness of this method with \textcolor{red}{two} vortical flow data sets and the scalability of our system in a distributed environment. 